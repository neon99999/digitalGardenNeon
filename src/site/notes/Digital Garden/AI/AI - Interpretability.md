---
{"dg-publish":true,"permalink":"/digital-garden/ai/ai-interpretability/","updated":"2023-12-06T16:37:28.000-07:00"}
---

AI interpretability refers to the ability of humans to understand how an AI system arrives at its decisions or recommendations. This is important because as AI systems become more advanced and are used in increasingly complex decision-making scenarios, it becomes harder for humans to understand how the AI system is making its decisions. Interpretability is critical for ensuring that AI systems are trustworthy, transparent, and aligned with human values.