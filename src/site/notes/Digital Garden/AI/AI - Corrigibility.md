---
{"dg-publish":true,"permalink":"/digital-garden/ai/ai-corrigibility/","updated":"2023-12-06T16:37:25.000-07:00"}
---

- Corrigibility refers to the ability of an AI system to recognize when its goals or behavior are problematic and to cooperate with human operators in order to correct these issues. 
- In other words, a corrigible AI system would be willing to modify its own objectives or behavior if it becomes aware that they are causing harm or running counter to human values.
- Ensuring that an AI system is corrigible requires designing the system with the ability to reason about its own limitations, to seek out feedback from human operators, and to modify its own objectives or behavior as needed. 
- Achieving corrigibility is particularly difficult because it requires designing an AI system that is not only intelligent but also self-reflective and able to reason about its own decision-making processes.
- in engineering and manufacturing, corrigibility is often built into systems to ensure that they can be quickly and easily adjusted or repaired if something goes wrong. In medicine, the concept of corrigibility is important for ensuring that diagnoses and treatments can be modified if new information or test results become available.